\documentclass[12pt,draftclsnofoot,journal,onecolumn]{IEEEtran}
\usepackage{amsfonts}
\usepackage{amsmath,amssymb}
\usepackage{acronym}  % make an acronym
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{balance}
\usepackage{bm}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage{color, soul}
\usepackage{cite}
\usepackage{flushend}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{subfigure}
\usepackage[amsmath,thmmarks]{ntheorem}
\usepackage{theorem}
% Enable Hyper-references.
\usepackage{hyperref}
\hypersetup{hidelinks, 
colorlinks=true,
allcolors=black,
pdfstartview=Fit,
breaklinks=true}

\newtheorem{theorem}{\bf Theorem}
\newtheorem{proposition}{\bf Proposition}
\newtheorem{lemma}{\bf Lemma}
\newtheorem{definition}{Definition}
\newtheorem{remark}{\bf Remark}

\theoremheaderfont{~~~\it}\theorembodyfont{\upshape}%
\theoremstyle{nonumberplain}
\theoremseparator{}
\theoremsymbol{\rule{1ex}{1ex}}
\newtheorem{proof}{Proof:}
\acrodef{EAR}[EAR]{element activation ratio}
\acrodef{SNR}[SNR]{signal-to-noise ratio}
\acrodef{TC}[TC]{transmission coefficients}
\acrodef{US-RIS}[US-RIS]{user-side RIS}
\acrodef{BSS-RIS}[BSS-RIS]{base-station-side RIS}
\acrodef{DoF}[DoF]{degree of freedom}
\acrodef{FPGA}[FPGA]{field programmable gate array}
\acrodef{RF}[RF]{radio-frequency}
\acrodef{RIS}[RIS]{reconfigurable intelligent surfaces}
\acrodef{UE}[UE]{user equipment}
\acrodef{BS}[BS]{base station}
\acrodef{DL}[DL]{downlink}
\acrodef{TA}[TA]{transmit antenna}
\acrodef{RA}[RA]{receive antenna}
\acrodef{LoS}[LoS]{line-of-sight}
\acrodef{UL-TBF}[UL-TBF]{uplink transmit beamforming}
\acrodef{TPS}[TPS]{transmit phase shifter}
\acrodef{RC}[RC]{receiver combining}
\acrodef{AWGN}[AWGN]{additive white Gaussian noise}
\acrodef{DFT}[DFT]{discrete Fourier transform}
\acrodef{IRF}[IRF]{interference random field}
\acrodef{MISO}[MISO]{multiple-input single-output}
\acrodef{CSI}[CSI]{channel state information}

\def \H {^H}
\def \opt {^{\text{opt}}}
\def \v {\bm v}
\def \w {\bm w}
\def \g {\bm g}
\def \f {\bm f}
\def \T {\bm \Theta}
\def \t {\bm \theta}
\def \x {\bm \xi}
\def \Pmax {P_{\text{max}}}
\def \ml {multi-layer }
\def \tb {transmit beamformer }
\def \sl {single-layer }
\def \diag {\text{diag}}
\def \opt {^{\text{opt}}}
\def \exp {\text{exp}}
\def \arg {\text{arg}}
\def \CN {\mathcal{CN}}
\def \VM {\mathcal{VM}}
\def \re {\rm Re}
\def \nc {\mathcal{NC}}

\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}   %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}}  %UseOutput in the format of Algorithm
\newcommand{\myincludegraphics}[2][width=12cm]{\includegraphics[#1]{#2}}

\ifCLASSINFOpdf
\else
\fi
\hyphenation{op-tical net-works semi-conduc-tor}
\begin{document}
\title{Sensing RIS}
\author{{Jieao Zhu, Kunzan Liu, Zhongzhichao Wan, and Linglong Dai
\vspace*{-1em}}
\thanks{All authors are with the Beijing National Research Center for Information Science and Technology (BNRist) as well as the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mails: \{zja21, lkz18, wzzc20\}@mails.tsinghua.edu.cn, daill@tsinghua.edu.cn).}
%\thanks{Corresponding author: Linglong Dai.}
}

\maketitle

\begin{abstract}
xxx
\end{abstract}

\begin{IEEEkeywords}
xxx
\end{IEEEkeywords}
\section{Introduction}
    In this paper, we introduce a new flavor of channel estimation and beamforming techniques in \ac{RIS}-aided wireless communication systems. When equipped with a Sensing \ac{RIS} \cite{ma2020smartsensing}, we can obtain CSI directly from the \ac{RIS} power sensors, and immediately calculate the beamforming phases for each \ac{RIS} element.

    There are five most significant benefits when using a Sensing-RIS system:
    \begin{itemize}
        \item The \ac{IRF} generated by the BS and UE makes it possible to obtain CSI with only one pilot symbol. Thus, the pilot overhead is reduced to $\mathcal{O}(1)$, independent of the number of RIS elements $N$. 
        \item After measuring the \ac{IRF} by the integrated power sensors, it is possible to directly calculate the optimal phase for each \ac{RIS} element within $\mathcal{O}(1)$ time. However, traditional channel estimation schemes require at least $\mathcal{O}(N)$ time, since the scale of the estimation problem is at least $\mathcal{O}(N)$.
        \item Both the CSI acquisition and beamforming can be done immediately at the \ac{RIS}, thus making channel feedback and BS signal processing unnecessary.
        \item Compared to attaching RF chains to the RIS elements\cite{zhang2021channel}, power sensors are much more cost-efficient and energy-efficient, since power sensors do not include LNAs, mixers and complicated baseband signal processors which turn out to be  essential for RF chains.
        \item The \ac{IRF} channel estimation and beamforming method is not affected by near-field effect, since this method does not rely on the prior knowledge of how the BS-RIS and RIS-UE channels are structured. 
    \end{itemize}

\section{System Model}  \label{System Model}
    In this section, we will first specify the system model of the RIS-assisted \ac{MISO} system, and introduce traditional approaches for the corresponding beamforming design and channel estimation in Subsection~\ref{MISO case}. Then, the signal model of the \ac{IRF} on the RIS will be introduced in Subsection~\ref{Models for IRFs}.

    \subsection{RIS-Aided MISO System}  \label{MISO case}
        Let us consider a RIS-aided MISO system, where an $N$-element RIS is employed for enhancing the transmission from an $M$-antenna \ac{BS} to a single-antenna user. Assume furthermore that the phase-shift of RIS's each element can be continuously and independently controlled \cite{wu2019intelligent}. Then, the RIS precoding matrix can be represented by
        \begin{equation}
            \label{RIS}
            \bm \Theta = \diag \left(\bm \theta\right )=\diag \left(\left[\theta_{1},\cdots ,\theta_{N}\right]^{T}\right),
        \end{equation}
        where $\theta_i (i\in[N])$ denotes the phase-shift of the $i$-th \ac{RIS} element, satisfying $\lvert \theta_i\rvert=1$. Therefore, the signal received by the user can be written as 
        \begin{equation}
            \label{Signal model}
            y=\bm f^{H} \bm\Theta \bm G \bm w s+z,
        \end{equation}
        where $\bm f\in \mathbb C ^{N\times 1}$ and $\bm G \in \mathbb C^{N\times M}$ denote the channel spanning from the \ac{RIS} to the user and the channel spanning from the BS to the \ac{RIS}, respectively; $\bm w\in \mathbb C^{M\times 1}$ denotes the beamforming vector at the transmitter BS, with power constraint $\left\Vert \bm w\right \Vert_{2}^{2}\leq P_{\text{max}}$; $s$ denotes the normalized transmitted symbol; $z\sim \mathcal{CN}\left(0,\sigma_{z}^{2}\right)$ denotes the \ac{AWGN} introduced at the receiver user. To focus on RIS precoding, other possible links are neglected in this paper.
        
        \subsubsection{Beamforming design}
        Based on the received signal \eqref{Signal model}, we can formulate the \ac{SNR} maximization problem for designing the beamforming vector $\bm w$ and precoding matrix $\bm \Theta$, i.e.,
        \begin{subequations}
\label{optimization}
\begin{align}
\label{objective}
\max_{\bm \Theta}~~&\text{SNR}=\frac{1}{\sigma_{z}^{2}}
\left\vert
\bm f^{H}\bm \Theta\bm G\bm w \right\vert^{2},\\
\label{constraint}
~~~~~\text{s.t.~~~}&\text{C}_{1}: \left\Vert \bm w\right \Vert_{2}^{2}\leq P_{\text{max}},\\
&\text{C}_{2}: \left\vert\theta_{n}\right\vert=1,~\forall n.
\end{align}
\end{subequations}
        
        
        In this paper, we assume that the locations of the \ac{BS} and the \ac{RIS} are unchanged, which can provide us a beamforming approach expressed as
                \begin{subequations}
\label{traditional beamforming}
\begin{align}
\label{w_optimal}
&\bm w=\sqrt{P_{\rm max}}\bm a\left(\alpha\right),\\
\label{theta_optimal}
&\theta_{n} = \exp\left(-{\rm j} \arg\left(f_{n}^{*}\bm g_{n}^{T}\bm w\right)\right),~\forall n\in [N],
\end{align}
\end{subequations}
where $\bm a(\alpha)$ denotes the array steering vector with respect to the wave departure angle $\alpha$ of the BS antenna array, and $\bm G = \left[\bm g_{1}, \cdots, \bm g_{N}\right]^{T}$.

\subsubsection{Channel estimation}
Observe from \eqref{traditional beamforming} that, the estimation for the cascade channel ${\bm H} = {\rm diag}({\bm f}^{*})\bm G$ is enough for beamforming design.
To accurately acquire this cascade channel, the user generally sends pilot signal $x$ to the BS under $P$ different RIS configurations which are the first $P$ columns of the DFT matrix $\bm F_{N,K}$. Due to the channel reciprocity, the received signal at the BS with the $p$-th RIS configuration $\bm \Theta_{p}$ can be written as \cite{atapattu2020reconfigurable}
    \begin{equation}
    \label{CE received signal}
    \begin{aligned}
            {\bm y}_{{\rm BS}, p} &={\bm G}^{T} {\bm \Theta}_p\bm f^{*} x+\bm n
            \\&=\bm H^{T} {\bm \theta}_p x+\bm n,
    \end{aligned}
    \end{equation}
    where $\bm n\sim \mathcal{CN}\left( \bm 0_{M}, \sigma_{n}^{2}\bm I_{M}\right)$ is the \ac{AWGN} at the receiver BS.
Equivalently, \eqref{CE received signal} can be expressed as the matrix form
    \begin{equation}
    \label{eqn:MMSE_CE}
        {\bm Y}_{\rm BS}=\bm H^{T} \bm F_{N,K}x + {\bm N},
    \end{equation}
    where ${\bm Y}_{\rm BS}=\left[\bm y_{{\rm BS}, 1},\cdots,\bm y_{{\rm BS}, P}\right]$ and $\bm N = \left[ \bm n_{1},\cdots,\bm n_{P}\right]$.
With the received signal $\bm Y_{\rm BS}$ and assuming $x=1$, the channel estimation in RIS-assisted system can be formulated as 
    \begin{equation}
        \hat{\bm H} = \arg\max_{\bm H} \lVert {\bm Y}_{\rm BS} - {\bm H^{T}} {\bm F}_{N,K}\rVert_{F}^2.
    \end{equation}
    With the least-square criterion, we obtain
    \begin{equation}
        \hat{\bm H} = \frac{1}{P}{\bm F}_{N,K}^{*}{\bm Y}_{\rm BS}^{T},
    \end{equation}
    which provides a solution for channel estimation in this system.

\subsection{Signal Model for IRF}
\label{Models for IRFs}
    Interference field at the $n$-th RIS element, with both of the  \ac{BS} and \ac{UE} transmitted symbols being $s=1$. Then the interference signal that appeared on each RIS element can be represented by its baseband equivalent signal
    \begin{equation}
    \label{interference}
    E_{n,{\rm BB}}(t)=\bm g_{n}^{T}\bm w+f_{n}^{*}e^{{\rm j}\psi (t)}+v(t).
    \end{equation}
    Thus, the corresponding passband electric field induced on each RIS element is represented by 
    \begin{equation}
        E_{n}(t) = \sqrt{2} {\rm Re}\left( E_{n,{\rm BB}}(t)e^{{\rm j}\omega_c t} \right),
    \end{equation}
    where $\omega_c = 2\pi f_c$ denotes the carrier frequency, and the coefficient $\sqrt{2}$ ensures that the passband signal energy is equal to the baseband signal energy. 

    Define $\alpha = \left\vert\bm g_{n}^{T}\bm w\right\vert$ and $\beta = \left\vert f_{n}^{*}\right \vert$, and define the phase to be estimated as $\varphi = \arg\left(f_{n}^{*}\right)-\arg\left(\bm g_{n}^{T}\bm w\right)$. Then, the power of interference field can be written as
    \begin{equation}
        \label{Power of Interference}
        \begin{aligned}
            P(t)&=A \left| E_{n, {\rm BB}} (t)\right |^{2}+\zeta\\
            &=\underbrace{A\left[\alpha^{2}+\beta^{2}+2\alpha\beta\cos\left(\psi(t)+\varphi\right)\right]}_{\text{Sensor detection signal}}\\
            &~~~+\underbrace{2A\text{Re}\left\{\left(\alpha+\beta e^{j\left(\psi(t)+\varphi\right)}\right)v'^{*}(t)\right\}+A\left|v'(t)\right|^{2}+\zeta}_{\text{Noise}},\\
        \end{aligned}
    \end{equation}
    where $v'\overset{\text{d}}{=}v\sim\mathcal{CN}\left(0,\sigma_{v}^{2}\right)$, and $\zeta$ is the signal processing noise after measuring the field power. 

    To estimate the phase $\varphi$, we need enough observations from the sensor-detected power signal $P(t)$. For simplicity and without loss of generality, we can assume $\psi(t)=\omega t$ and $\omega=\frac{2\pi}{T_{s}}$. Furthermore, assume that $L$ observations $P[l]=P(t_{l})$ at equally-spaced instants 
    \begin{equation}
        \label{observation time}
        t_{l}=\frac{l}{L}T_{s},~\forall l\in \left\{0,\cdots ,L-1\right\}
    \end{equation}
    are used for estimation of $\varphi$.

\section{Channel Estimation with Interference Random Fields}
\subsection{How can IRF Perform Channel Estimation?}
    It is widely known that most of the existing channel estimation methods employ the transceivers as the explorers of CSI. The transmitter emits EM waves, which imping the RIS, and the bounced-back waves enter the receiver, telling us what the channel is. It seems that we are using EM waves to probe the radio environment. However, for RIS-aided systems, the channel may have up to thousands of free parameters, which makes the probing process extremely inefficient, especially when the transceivers are only equipped with dozens of antennas. That's like shedding a few beams of light into a blackbox and trying to distinguish thousands of objects inside, which is intrinsically intricate. Apparently, a more reasonable way is just simply to place our probes inside the blackbox. That is why we want to attach power sensors to the RIS. 

    However, how can these low-cost power sensors obtain key information about the CSI? Take only one RIS element into consideration. If we allow the BS and UE to emit EM waves simultaneously, then interference will occur, and interference fringes will appear on the RIS. Thus, if we alter the phase at the UE, the interference fringes will change, allowing the power sensors on the RIS to obtain CSI. 
    \begin{figure}[htbp]
        \centering
        \myincludegraphics{figures/scheme.pdf}
        \caption{MISO communication scheme which is considered in this paper. Colorful shadings on the RIS represent the interference fringes; Yellow points on the RIS represent the power sensors.}
        \label{fig:scheme}
    \end{figure}
    To further analyze the interference, we focus on the received field of the $n$-th RIS element. Note that the power of interference field measured at instant $t$, expressed by \eqref{Power of Interference}, exhibits a sinusoidal waveform. The phase of this sinusoidal waveform is uniquely determined by $\varphi$, i.e., the phase difference between the RIS-UE channel ${\bm f}_n^{*}$ and the BS-RIS channel ${\bm g}_n^{\rm T}{\bm w}$. Thus, if we have access to the power received by the $n$-th element at successive instants $t_l$, it is possible to retrieve the phase difference $\varphi$. However, it is the phase sum of the RIS-UE channel and the BS-RIS channel that determines the optimal phase-shift of the $n$-th element. Given the phase difference, in order to acquire the phase sum, we only need to obtain one of the phases of these two channels to perform optimal RIS beamforming. Though generally it is difficult to obtain the BS-RIS channel and the RIS-UE channel, since the BS and RIS are installed at fixed locations, it is reasonable to assume that the BS-RIS channel is much more stable and predictable, compared to the RIS-UE counterpart. As a result, the phases of the BS-RIS link $\arg({\bm g}_n^{\rm T}{\bm w})$ can be assumed to be known in our algorithms. Due to the stability of this channel, the phases are mainly determined by geometric parameters, i.e., the location of the BS and RIS. 

\subsection{IRF Channel Estimation and Beamforming}
    \begin{algorithm}[H] 
        \caption{Near-optimal RIS Beamforming by IRF} \label{alg:IRF-Beamforming}
        \setstretch{1.35}
        \begin{algorithmic}[1]
            \REQUIRE Number of RIS elements $N$, power signals detected on each RIS element $P_n(t)$.
            \ENSURE RIS phase-shift matrix ${\bm \Theta}$.
            \FOR{$n=1,2,\cdots,N$}
                \STATE $\varphi_n \leftarrow$ estimate phase difference  $\arg\left(f_{n}^{*}\right)-\arg\left(\bm g_{n}^{\rm T}\bm w\right)$ from $P_n(t)$
                \STATE $\psi_{n} \leftarrow$ estimate phase-shift of $\bm g_{n}^{\rm T}\bm w$ from geometric parameters of BS and RIS
                \STATE $\theta_n \leftarrow -\varphi_n - 2\psi_n$
            \ENDFOR
            \STATE ${\bm \Theta} \leftarrow \diag(\theta_1, \theta_2, \cdots, \theta_N)$
            \RETURN ${\bm \Theta}$
        \end{algorithmic}
    \end{algorithm}
    The overall channel estimation and beamforming procedure is described in {\bf Algorithm \ref{alg:IRF-Beamforming}}. Note that in each iteration of the algorithm, the data are unrelated to other iterations. Thus, we can perform the calculations in parallel for each phase-shift $\theta_n$. For example, we can install an MCU for each of the elements on the RIS. Each MCU is only responsible for gathering the data from its own power sensor and adjusting the phase-shift of its own RIS element. Since all MCUs can work in parallel, the computational time is independent of the number of RIS elements, resulting in an $\mathcal{O}(1)$-time RIS beamforming algorithm. 

    The pilot overhead is also $\mathcal{O}(1)$. The reason is that, no matter how many RIS elements are employed, the IRF appears on them simultaneously. Thus, both the channel estimation and beamforming can be fulfilled within only one pilot symbol. 

    However, the $\mathcal{O}(1)$ time complexity only holds when an MCU is installed for each RIS element. If all the RIS elements are collectively controlled by one processor, the computational time would be of order $\mathcal{O}(N)$, but the pilot overhead is still $\mathcal{O}(1)$. These conclusions of complexity can be easily extended to multi-RIS schemes, where multiple RISs are employed to serve a single user at the same time. The independent nature of IRF methods allows the RISs to work without the need to exchange data with the BS or other RISs. This property makes it much easier to integrate a new RIS into an existing communication system, which greately enhances the extendibility of the system. Specifically, the new RIS can start to work and strengthen the communication links immediately after its installation, just like a plug-and-play USB device. 

\subsection{LS method}
    The key challenge of the IRF channel estimation and beamforming is how to obtain the phase difference $\varphi$. Since the interferential power $P_n(t)$ exhibits a sinusoidal waveform, Fourier transforms can be applied to extract its phase. Apply $L$-point \ac{DFT} to the observed sensor detection signals $P[0],\cdots ,P[L-1]$, and we have
    \begin{equation}
        \label{DFT}
        p[l']=\sum\nolimits_{l=0}^{L-1}P[l]e^{-{\rm j}\frac{2\pi}{L}ll'},~\forall l'\in [L].
    \end{equation}
    Specifically, we have the complex amplitude of the first harmonics $p[1]$ as 
    \begin{equation}
        \label{DFT l=1}
        p[1]=\sum\nolimits_{l=0}^{L-1}A\left[\alpha^{2}+\beta^{2}+2\alpha\beta\cos\left(\frac{2\pi}{L}l+\varphi\right)\right]e^{-j\frac{2\pi}{L}l}=LA\alpha\beta  e^{j\varphi}.
    \end{equation}
    Then, the phase $\varphi$ can be estimated as
    \begin{equation}
        \label{LS estimate result}
        \hat{\varphi}=\arg\left(\frac{p[1]}{LA\alpha\beta}\right) = \arg\left(p[1]\right).
    \end{equation}

%% zja working below
\subsection{ML method}
    Suppose the noise field $v'(t)=v'_R(t) + jv'_I(t)\sim \mathcal{CN}(0, \sigma_v^2)$, and the noise of the power sensor is $\zeta \sim \mathcal{N}(0, \sigma_{\zeta}^2)$. Then the distribution of $s(t) := A\left|E_n(t)\right|^2$ is a noncentral chi-squared distribution with degrees of freedom $k=2$, and mean values $\mu_{n,R}, \mu_{n,I}$ given by
                    \begin{subequations}
\label{chi2 distribution mean values}
\begin{align}
\label{mu_n,R}
\mu_{n,R} & = \alpha + \beta \cos(\psi(t)+\varphi),\\
\label{mu_n,L}
\mu_{n,I} & = \beta \sin(\psi(t)+\varphi).
\end{align}
\end{subequations}
    Thus, the output of the power sensor is 
    \begin{equation}
        P(t)  = A\left((v'_{R} + \mu_{n,R})^2 + (v'_{I} + \mu_{n,I})^2 \right)+ \zeta 
        \label{eqn:sensor power}
    \end{equation}
    Let us define the noncentral parameter $\lambda(t)$ as
    \begin{equation}
        \lambda(t)  = A(\mu_{n,R}^2 + \mu_{n,I}^2) = A\left[\alpha^{2}+\beta^{2}+2\alpha\beta\cos\left(\psi(t)+\varphi\right)\right],
    \end{equation}
    then the p.d.f of $s(t) := P(t)-\zeta$ is given by the zeroth-order modified Bessel function
    \begin{equation}
        f_{s(t)}(x) = \frac{1}{A\sigma_{v}^2} \exp\left(-\frac{x+\lambda(t)}{A\sigma_v^2}\right)I_{0}\left(\frac{\sqrt{\lambda(t) x}}{A\sigma_v^2/2}\right),\quad x \geq 0.
        \label{ML single observation}
    \end{equation}
    In the following analysis, we assume that $\sigma_{\xi}^2 = 0$. If we have obtained observations $P[l], \forall l\in [L]$, then the log likelihood function is given by
    \begin{equation}
        \mathcal{L}(P[0:L] | \varphi) = \sum_{l=0}^{L-1}\left[-\frac{P[l] + \lambda_l}{A\sigma_v^2} + \log I_0\left(\frac{\sqrt{P[l] \lambda_l}}{A\sigma_v^2/2}\right)\right] - L\log(A\sigma_v^2),
        \label{ML likelihood}
    \end{equation}
    where $\lambda_l := \lambda(t_l)$, and the derivative of \eqref{ML likelihood} is 
    \begin{equation}
        \frac{\partial \mathcal{L}(P[0:L] | \varphi)}{\partial \varphi} = \frac{2\alpha\beta}{\sigma_v^2}\sum_{l=0}^{L-1}\sin(\psi(t_l)+\varphi) \left[1 - R\left( \frac{\sqrt{P[l]\lambda_l}}{A\sigma_v^2/2} \right) \frac{\sqrt{P[l]}}{\sqrt{\lambda_l}}\right],
    \end{equation}
    where the function $R(z)$ is defined as $R(z) = I_1(z)/I_0(z)$. Since the derivative of the function $R(z)$ satisfies the property
    \begin{equation}
        R'(z)=1-R^2(z)-\frac{1}{z}R(z),
    \end{equation}
    the second derivative of the likelihood function $\mathcal{L}$ can be expressed as
    \begin{equation}
        \begin{aligned}
        \frac{\partial^2 \mathcal{L}(P[0:L] | \varphi)}{\partial \varphi^2}  = &  \frac{2\alpha\beta}{\sigma_v^2} \sum_{l=0}^{L-1}{\cos(\psi(t_l)+\varphi)}\left[1 - R\left(z_l\right) \frac{\sqrt{P[l]}}{\sqrt{\lambda_l}}\right] \\
        & +\frac{4\alpha^2\beta^2}{\sigma_v^4}\sum_{l=0}^{L-1}{\sin^2(\psi(t_l)+\varphi) \left(1-R^2(z_l) -\frac{2}{z_l}R(z_l)\right)\frac{P[l]}{\lambda_l} },\\
        \end{aligned}
        \label{Second Derivative Likelihood}
    \end{equation}
    where
    \begin{equation}
        z_l = \sqrt{P[l]\lambda(t_l)}/(A\sigma_v^2/2).
        \label{eqn:def z_l}
    \end{equation}
    Then, we can perform the Newton iteration to obtain $\hat{\varphi}$, by iteratively using
    \begin{equation}
        \hat{\varphi}^{(k+1)} = \hat{\varphi}^{(k)} - \frac{\mathcal{L}'(\hat{\varphi}^{(k)})}{\mathcal{L}''(\hat{\varphi}^{(k)})}.
    \end{equation}

\subsection{CRLB}
    The evaluation of CRLB in non-coherent parameter estimation was first formulated in \cite{jiang2016cramer}, where the authors introduced Gaussian approximation in order to obtain a simple closed-form CRLB expression. However, without Gaussian approximation techniques we have to deal with the operations of many Bessel functions, and thus the analysis becomes nearly intractable. In contrast, in this paper, this difficulty is overcomed by asymptotic expansion techniques (cite here). Though precise expression of CRLB is still not obtained, satisfactory asymtotic results are acquired. 
    
    
    % TODO: Write a theorem here.
    \begin{theorem}[Asymptotic Evaluation of Non-Central Chi-Squared CRLB]
        Suppose the probabilistic model is specified by \eqref{eqn:sensor power}. Then the CRLB of this $L$-point phase estimation problem is given by 
        \begin{equation}
            \frac{1}{{\rm CRLB}(\varphi)}\approx K^2(\bar{\gamma})^2 \sum_{l=0}^{L-1}\sin^2(\psi_l+\varphi)(1/\gamma_l-\hat{g}(\gamma_l))^{+},
        \end{equation}
        where $K=2\alpha\beta/(\alpha^2+\beta^2)$, $a=A\sigma_v^2$, $\gamma_l=\lambda_l/a$, and $\bar{\gamma}$ is the arithmetic mean of all the $\gamma_l, 0\leq l<L$. The function $\hat{g}(\gamma)$ is defined as 
        \begin{equation}
            \hat{g}(\gamma) = \frac{1}{4} \sqrt{\frac{\pi}{\gamma}}e^{-\gamma/2}\left((1+1/\gamma)I_0(\gamma/2) + I_1(\gamma/2)\right).
            \label{eqn:definition g function}
        \end{equation}
    \end{theorem}

   The best prediction accuracy occurs when $\lvert K \rvert = 1$, i.e., the RIS-received signal from BS is as strong as that from UE. Note that in \eqref{eqn:CRLB_simple}, due to the symmetry of the $\sin^2(\cdot)$ function, the accuracy $1/{\rm CRLB}(\varphi)$ is only a function of $\bar{\gamma}$ and $\lvert K \rvert$. Thus, we can plot $1/{\rm CRLB}(\varphi)$ as a two-variable function:
    \begin{figure}[!h]
        \centering
        \myincludegraphics{figures/crlb.pdf}
        \caption{CRLB}
    \end{figure}

\subsection{von Mises-EM method}
    We discover from our experiments that both the LS method and the Newton-ML method are close to the CRLB. Specifically, the Newton-ML method provides an almost optimal estimator for the phase difference $\varphi$ between the BS-RIS path and the RIS-User path. However, the computation of the Newton-ML estimator is quite complicated due to intensive calculation of modified Bessel functions. Now we introduce an iterative method for estimating $\varphi$ without any computation of special functions.

    This algorithm is based on the Bayesian inference of von-Mises distributions. The von-Mises distribution $VM(\mu, \kappa)$ is a two-parameter distribution on $[0, 2\pi]$, with the probability density function given by 
    \begin{equation}
        p(\theta|\mu, \kappa) = \frac{\exp(\kappa \cos(\theta - \mu))}{2\pi I_0(\kappa)}, 0\leq \theta \leq 2\pi,
    \end{equation}
    where $\mu \in [0,2\pi]$ and $\kappa >0$ being the cyclic location parameter and the concentration parameter. The von-Mises distribution is closely related to the complex Gaussian distribution.
    
    \begin{lemma}[Bayesian estimation of von-Mises distribution]\label{lemma_1}
        Let $\theta \sim \VM(\mu, \kappa)$, and $z \sim \CN(e^{{\rm j}\theta}, \sigma^2)$. Then the posterior distribution $\theta | z$ is also a von-Mises distribution $\VM(\mu', \kappa')$ with parameters $\mu'$ and $\kappa'$ satisfying
        \begin{equation}
            \kappa' e^{{\rm j}\mu'} = \kappa e^{{\rm j}\mu} + \frac{1}{\sigma^2/2}z.
        \end{equation}
    \end{lemma}
    \begin{IEEEproof}
        Since $z=z_r + {\rm j} z_i \sim \CN(e^{{\rm j} \theta}, \sigma^2)$, the conditional density for $z|\theta$ is given by 
        \begin{equation}
            p(z|\theta) = \frac{1}{\sigma^2}\exp\left(-\frac{1}{\sigma^2}\left(\left(z_r - \cos\theta\right)^2 + \left(z_i - \sin\theta\right)^2\right)\right)
        \end{equation}
        The posterior density $p(\theta | z) \propto p(\theta)p(z|\theta)$. Thus
        \begin{equation}
            \begin{aligned}
                p(\theta|z) & \propto \exp(\kappa \cos(\theta - \mu))\exp\left(-\frac{1}{\sigma^2}\left(\left(z_r - \cos\theta\right)^2 + \left(z_i - \sin\theta\right)^2\right)\right) \\
                & \propto \exp\left( \kappa \cos(\theta - \mu) + \frac{2}{\sigma^2}(z_r \cos\theta + z_i\sin\theta) \right) \\
                & \propto \exp\left( \re\left[ \kappa e^{{\rm j} (\theta - \mu)} + \frac{1}{\sigma^2/2}z^{*} e^{{\rm j} \theta} \right] \right) \\
                & = \exp\left( \re\left[ e^{{\rm j} \theta}\left(\kappa e^{-{\rm j}\mu} + \frac{1}{\sigma^2/2} z^*\right)\right] \right).
            \end{aligned}
        \end{equation}
        Since the density of von-Mises distribution $\VM(\mu, \kappa)$ can also be expressed as $p(\theta) \propto \exp\left( \re\left[ e^{{\rm j} \theta}(\kappa e^{{\rm j} \mu})^* \right] \right)$, we can also parameterize the von-Mises distribution by a single complex parameter $\kappa e^{{\rm j}\mu}$. Thus, the above $p(\theta|z)$ is a von-Mises density with parameter $\kappa'e^{{\rm j}\mu'}$, satisfying $\kappa' e^{{\rm j}\mu'} = \kappa e^{{\rm j}\mu} + 1/(\sigma^2/2)\,z$. This completes the proof.
    \end{IEEEproof}
    From the above proof, we can also denote the von-Mises distribution $\VM(\mu, \kappa)$ as $\VM(\kappa e^{{\rm j}\mu})$. This representation is more convenient when manipulating the posterior distributions in Bayesian inference.

    \begin{lemma}[Noncentral $\CN$ posterior distribution on circle is $\VM$]\label{lemma_2}
        Suppose $z \sim \CN(z_0, \sigma^2)$, where $z_0 \in \mathbbm{C}$, and a positive radius $r>0$. Then the posterior distribution of angle $\theta= \arg (z)$ on a circle $|z|=r$ obeys the von-Mises distribution
        \begin{equation}
            p(\theta |\, |z|=r) \sim \VM\left(\arg(z_0), \frac{r|z_0|}{\sigma^2/2}\right).
        \end{equation}
    \end{lemma}
    \begin{IEEEproof}
        Trivial.
    \end{IEEEproof}
    Combining the results of {\bf Lemma \ref{lemma_1}} and {\bf Lemma \ref{lemma_2}}, we can construct the EM algorithm for estimating $\varphi$. Since the output of the power sensors $P[l]$ does not contain phase information, we can treat the phases as latent variables. Let $s_l = \sqrt{P[l]/A}$ be the noisy estimation for $|\alpha + \beta e^{{\rm j} (\varphi + \psi_l)} + v_l|$, and $\theta_l$ be the latent variables $\arg (\alpha + \beta e^{{\rm j} (\varphi + \psi_l)} + v_l)$. Since the noise $v_l \sim {\rm i.i.d.}\;\CN(0, \sigma_v^2)$, then from {\bf Lemma \ref{lemma_2}}, $\theta_l | s_l, \varphi \sim \VM(\arg(\alpha + \beta e^{{\rm j} (\varphi + \psi_l)}), s_l |\alpha + \beta e^{{\rm j} (\varphi + \psi_l)}|/(\sigma_v^2/2))$. Thus, we can infer the latent variables by ML estimation 
    \begin{equation}
        \hat{\theta}_{l, {\rm ML}} | s_l, \varphi = \arg(\alpha + \beta e^{{\rm j} (\varphi + \psi_l)})
        \label{eqn:E-step}
    \end{equation}
    After inferring the latent variables $\hat{\theta}_{l, {\rm ML}}$, we can update the estimation of $\varphi$ using Bayesian rule in {\bf Lemma \ref{lemma_1}}
    \begin{equation}
        \varphi | s_l, \theta_l \sim \VM\left( \kappa e^{{\rm j} \mu} + \frac{1}{\beta\sigma_v^2/2}\sum_{l=0}^{L-1}{\left(s_l e^{{\rm j}\theta_l}-\alpha\right)e^{-{\rm j} \psi_l}}\right)
        \label{eqn:M-step}
    \end{equation}
    Performing E-step with \eqref{eqn:E-step} and M-step with \eqref{eqn:M-step} alternately, then the estimation precision for $\varphi$ can be iteratively improved. Note that although the modified Bessel functions appear in the density function of von-Mises distribution, the bother is avoided in the von Mises-EM algorithm.

    \begin{algorithm}[H] 
        \caption{von Mises-EM phase estimation} \label{alg:VM-EM}
        \setstretch{1.35}
        \begin{algorithmic}[1]
            \REQUIRE Incident wave intensity $\alpha$, $\beta$; sensor data $P[l]$; amplification factor $A$ and noise variance $\sigma_v^2$; predefined phase shifts $\psi_l$.
            \ENSURE $\hat{\varphi}$
            \STATE $s_l \leftarrow \sqrt{P[l]/A}, \forall l=0,1,\cdots,L-1$
            \STATE $\hat{\varphi} \leftarrow \arg\{{\rm FFT}(P)[1]\}$
            \STATE $\kappa \leftarrow 1$
            \WHILE {$\hat{\varphi}$ not convergence}
                \STATE $\mu_l \leftarrow \alpha + \beta e^{{\rm j} (\hat{\varphi}+\psi_l)}, \forall l=0,1,\cdots,L-1$
                \STATE $w_l \leftarrow s_l e^{{\rm j} \arg(\mu_l)} - \alpha, \forall l=0,1,\cdots,L-1$
                \STATE $z_\varphi \leftarrow \kappa e^{{\rm j} \hat{\varphi}} + \left( \sum_{l=0}^{L-1}{w_l e^{-{\rm j} \psi_l}}\right) / (\beta \sigma_v^2/2)$
                \STATE $\hat{\varphi} \leftarrow \arg(z_\varphi)$
                \STATE $\kappa \leftarrow |z_\varphi|$
            \ENDWHILE
            \RETURN $\hat{\varphi}$
        \end{algorithmic}
    \end{algorithm}

    However, in the above {\bf Algorithm \ref{alg:VM-EM}}, we need the interferential parameters $\alpha$ and $\beta$. In fact, these parameters are channel gains that can be directly measured without interference signaling of the BS and UE. 

\subsection{MIMO case: Generalization to Multiusers}

\appendices


\section*{Acknowledgments}
Thanks\dots 

\section*{Appendix A\\ Proof of Theorem 1}\label{appendix:proof of theorem1}
\begin{IEEEproof}
    In fact, taking the negative expectation of \eqref{Second Derivative Likelihood} yields the reciprocal CRLB of the estimators for $\hat{\varphi}$. Note that in \eqref{Second Derivative Likelihood}, there are three types of expectations to be evaluated: $\mathbb{E}\left[P[l]\right]$, $\mathbb{E}\left[R(z_l)\sqrt{P[l]}\right]$, and $\mathbb{E}\left[(1-R^2(z_l))P[l]\right]$. The evaluation of these expectation integrals are partially based on the properties of the non-central chi-square distribution. The expectation of $P[l]$ can be directly evaluated from \eqref{eqn:sensor power} by the linearity of the expectation operation:
    \begin{equation}
        \mathbb{E}\left[P[l]\right] = A\sigma_v^2 + \lambda_l,
        \label{eqn:expectation of P_l}
    \end{equation}
    and, in fact, the expectation $\mathbb{E}\left[R(z_l) \sqrt{P[l]}\right]$ can be evaluated by calculating the derivative w.r.t $\lambda_l$ on both sides of the identity $\mathbb{E}_{\lambda_l, A\sigma_v^2}[e^{\lambda_l/(A\sigma_v^2)}]=e^{\lambda_l/(A\sigma_v^2)}$:
    \begin{equation}
        \begin{aligned}
            \mathbb{E}\left[R(z_l) \sqrt{P[l]}\right] & = \int_{0}^{+\infty}{\frac{1}{A\sigma_v^2}\exp\left(-\frac{x+\lambda_l}{A\sigma_v^2}\right)I_1\left(\frac{\sqrt{\lambda_l x}}{A\sigma_v^2/2}\right)\sqrt{x}{\rm d}x}\\
            & = e^{-\lambda_l/(A\sigma_v^2)}\int_{0}^{+\infty}{\frac{1}{A\sigma_v^2}\exp\left(-\frac{x}{A\sigma_v^2}\right)I_1\left(\frac{\sqrt{\lambda_l x}}{A\sigma_v^2/2}\right)\sqrt{x}{\rm d}x} \\
            & = e^{-\lambda_l/(A\sigma_v^2)} A\sigma_v^2 \sqrt{\lambda_l} \frac{\partial}{\partial\lambda_l} \int_{0}^{+\infty}{\frac{1}{A\sigma_v^2}\exp\left(-\frac{x}{A\sigma_v^2}\right)I_0\left(\frac{\sqrt{\lambda_l x}}{A\sigma_v^2/2}\right) {\rm d}x}\\
            & = e^{-\lambda_l/(A\sigma_v^2)} A\sigma_v^2 \sqrt{\lambda_l} \frac{\partial}{\partial\lambda_l} \left(e^{\lambda_l/(A\sigma_v^2)}\right)\\
            & = \sqrt{\lambda_l}.\\
        \end{aligned}
        \label{eqn:expectation_second_kind_1}
    \end{equation}
    Note that, because of the definition of $z_l$ \eqref{eqn:def z_l}, the expectation $\mathbb{E}\left[R(z_l)P[l]/z_l\right]$ is, intrinsically, of the same form as the expectation $\mathbb{E}\left[R(z_l) \sqrt{P[l]}\right]$. The result is
    \begin{equation}
        \mathbb{E}\left[\frac{R(z_l)}{z_l} P[l]\right] = \frac{A\sigma_v^2}{2}.
        \label{eqn:expectation_second_kind_2}
    \end{equation}
    The third kind of expectation $\mathbb{E}\left[(1-R^2(z_l))\frac{P[l]}{\lambda_l}\right]$ is the trickiest to calculate. Although it has no closed-form expression, we evaluate it approximately by utilizing the asymptotic expansion $x(1-R^2(2\sqrt{x})) \approx \sqrt{x}/2$(cite here). Thus, by substituting $x=\lambda_lP[l]/a^2$ into the asymptotic expansion formula, we can further simplify the integrand of the expectation to be 
    \begin{equation}
        \begin{aligned}
            \mathbb{E}\left[(1-R^2(z_l))\frac{P[l]}{\lambda_l}\right] & \approx g(\lambda_l, a) \\ 
            & \triangleq  \frac{1}{4}\sqrt{\frac{\pi a}{\lambda_l^3}}e^{-\lambda_l/(2a)}\left((a+\lambda_l)I_0(\lambda_l/(2a))+\lambda_l I_1(\lambda_l/(2a))\right),
        \end{aligned}
        \label{eqn:trickiest_expectation}
    \end{equation}
    where $a=A\sigma_v^2 \ll \lambda_l$, $h(\lambda_l, a)$ is a two-variable function\footnote{In fact, the two-variable function $g(\lambda, a)$ can be further simplified into a single-variable function $g(\cdot). $}, and $I_\nu$ is the $\nu$-th order  modified Bessel function of the first kind. For detailed proof of the calculation process and error analysis of \eqref{eqn:trickiest_expectation}, please refer to {\bf Appendix B}. Combining the above equations of expectations \eqref{eqn:expectation of P_l}, \eqref{eqn:expectation_second_kind_1}, \eqref{eqn:expectation_second_kind_2} and \eqref{eqn:trickiest_expectation}, we obtain
    \begin{equation}
        \begin{aligned}
        \frac{1}{{\rm CRLB}(\varphi)} & = -\mathbb{E}\left[\frac{\partial^2\mathcal{L}}{\partial\varphi^2}\right] \\
        & \overset{(a)}{=}  -\frac{4\alpha^2\beta^2}{\sigma_v^4}\sum_{l=0}^{L-1}{ \sin^2(\psi(t_l)+\varphi) \left(\mathbb{E}\left[(1-R^2(z_l))\frac{P[l]}{\lambda_l}\right] - \frac{a}{\lambda_l}\right) } \\
        & \overset{(b)}{\approx} \frac{4\alpha^2\beta^2}{\sigma_v^4}\sum_{l=0}^{L-1}{ \sin^2(\psi(t_l)+\varphi) \left(\frac{a}{\lambda_l}-\hat{g}(\lambda_l/a)\right)^{+} },
        \end{aligned}
        \label{eqn:CRLB}
    \end{equation}
    where $(x)^{+}$ denotes $x \mathbbm{1}_{\{x \ge 0\}}$, step $(a)$ comes from substituting these three types of expectation into \eqref{Second Derivative Likelihood}, and step $(b)$ comes from replacing the trickiest expectation by its approximation $\hat{g}$, which is defined in \eqref{eqn:definition g function}.  The introduction of operation $(x)^{+}$ is due to the non-negativity of each of the $L$ CRLB components. 
    
    Note that \eqref{eqn:CRLB} is only an approximated CRLB. The true value of CRLB can be described by the precise single-variable $g$ function 
    \begin{equation}
        \begin{aligned}
            g(\gamma) &= \mathbb{E}_{\lambda_l, a}\left[(1-R^2(z_l))\frac{P[l]}{\lambda_l}\right] \\
            & = \int_{0}^{+\infty}\gamma t \,\exp(-\gamma(1+t))\, I_0\left(2\gamma\sqrt{t}\right)\,\left(1-R^2\left(2\gamma\sqrt{t}\right)\right){\rm d}t,
        \end{aligned}
        \label{eqn:precise_g_function}
    \end{equation}
    which is the precise version of $\hat{g}$. By replacing $g(\lambda_l/a)$ with $g(\gamma_l)$ where $\gamma_l = \lambda_l / a$ being the interferential SNR, it seems that the CRLB only relies on two intrinsic physical parameters: the interferential SNR $\gamma_l$, and the interferential contrast $K$(cite here). From the above intuitive thoughts, we define the parameter $K$ to be  
    \begin{equation}
        K = \frac{I_M - I_m}{I_M + I_m} = \frac{2\alpha\beta}{\alpha^2+\beta^2},
    \end{equation}
    and $K$ automatically satisfies $-1\leq K\leq 1$. Define the average interferential SNR $\bar{\gamma}$ to be the arithmetic average of $\gamma_l, 0\leq l < L$:
    \begin{equation}
        \bar{\gamma} = \frac{1}{L}\sum_{l=0}^{L-1}{\gamma_l} = \frac{\alpha^2+\beta^2}{\sigma_v^2}.
    \end{equation}
    Thus, the CRLB can be expressed as 
    \begin{equation}
        \begin{aligned}
            \frac{1}{{\rm CRLB}(\varphi)} &= K^2(\bar{\gamma})^2 \sum_{l=0}^{L-1}{ \sin^2(\psi_l+\varphi) \left(1/\gamma_l-g(\gamma_l)\right) }\\
            & \approx K^2(\bar{\gamma})^2 \sum_{l=0}^{L-1}{ \sin^2(\psi_l+\varphi) \left(1/\gamma_l-\hat{g}(\gamma_l)\right)^{+} }
        \end{aligned}
        \label{eqn:CRLB_simple}
    \end{equation}
    where the values $\gamma_l=\bar{\gamma}\left(1+K\cos(\psi_l+\varphi)\right)$ are jointly determined by both the average SNR $\bar{\gamma}$ and the interferential contrast $K$. This completes the proof.

\end{IEEEproof}


\section*{Appendix B\\ Expectation Evaluation and Error Analysis}\label{appendix: expectation evaluation}
    In order to evaluate the expectation $\mathbb{E}[(1-R^2(z_l))P[l]/\lambda_l]$, we first introduce some preliminaries about the noncentral chi distribution $\nc_{\chi_k}(\lambda)$ with noncentrality parameter $\lambda>0$. The distribution $\nc_{\chi_k}(\lambda)$ is the law of the length (2-norm) of a $k$-dimensional standard normal distribution $\mathcal{N}({\bm \mu}, {\bm I}_k)$, with $\lambda = \Vert {\bm \mu} \Vert_2$. Specifically, we are interested in the case where $k=2$, since this is the case of the 2-dimensional complex plane. For  $k=2$, let $Y \sim \nc_{\chi_2}(m)$, then we have (cite here)
    \begin{equation}
        \mathbb{E}\left[Y\right] = \sqrt{\frac{\pi}{2}}L_{1/2}(-m^2/2),
        \label{eqn:noncentral chi mean}
    \end{equation}
    where $L_{1/2}$ denotes the generalized Laguerre function of order $1/2$. The function $L_{1/2}(x)$ has explicit expression 
    \begin{equation}
        L_{1/2}(x) = e^{x/2}\left[(1-x)I_0\left(-\frac{x}{2}\right)-xI_1\left(-\frac{x}{2}\right) \right].
        \label{eqn:Laguerre half order}
    \end{equation}
    Recall that the asymptotic expansion holds for large $x$:
    \begin{equation}
        x(1-R^2(2\sqrt{x})) \sim \sqrt{x}/2,
        \label{eqn:asym_expansion}
    \end{equation}
    and the random variable $P[l]$ obeys a noncentral chi-squared distribution which can be equivalently expressed as 
    \begin{equation}
        P[l] \sim \frac{a}{2} \left| \CN\left((\alpha + \beta e^{{\rm j} (\phi_l + \varphi)})/(\sigma_v / \sqrt{2}), 2\right)\right|^2
    \end{equation}
    and $\left| \CN\left((\alpha + \beta e^{{\rm j} (\phi_l + \varphi)})/(\sigma_v / \sqrt{2}), 2\right)\right|$, in fact, obeys a noncentral chi distribution of dimension $k=2$ and noncentrality parameter $m=\lvert\alpha + \beta e^{{\rm j} (\phi_l + \varphi)}\rvert/(\sigma_v / \sqrt{2})$ Thus, we can convert the expectation  $\mathbb{E}[(1-R^2(z_l))P[l]/\lambda_l]$ into the expectation of a noncentral chi random variable:
    \begin{equation}
        \begin{aligned}
        \mathbb{E}[(1-R^2(z_l))P[l]/\lambda_l] & = \mathbb{E}\left[\left(1-R^2\left(\frac{\sqrt{\lambda P[l]}}{a/2}\right)\right)\frac{P[l]}{\lambda}\right] \\
        & \approx \left(\frac{a}{\lambda}\right)^2 \mathbb{E}\left[ \sqrt{\frac{\lambda P[l]}{a^2}}/2 \right]\\
        & = \frac{1}{2}\frac{\sqrt{\lambda}}{a}\left(\frac{a}{\lambda}\right)^2 \sqrt{\frac{a}{2}}\mathbb{E}\left[\nc_{\chi_2}(m)\right],\\
        \end{aligned}
        \label{eqn:approx evaluation}
    \end{equation}
    where $m=\lvert\alpha + \beta e^{{\rm j} (\phi_l + \varphi)}\rvert/(\sigma_v / \sqrt{2}) = \sqrt{2\lambda/a} = \sqrt{2\gamma}$, and thus $m^2/2=\gamma$. Plugging \eqref{eqn:noncentral chi mean} and \eqref{eqn:Laguerre half order} into \eqref{eqn:approx evaluation}, we obtain the final expression 
    \begin{equation}
        \begin{aligned}
        \mathbb{E}[(1-R^2(z_l))P[l]/\lambda_l] & \approx \frac{1}{2}\frac{\sqrt{\lambda}}{a}\left(\frac{a}{\lambda}\right)^2 \sqrt{\frac{a}{2}} \sqrt{\frac{\pi}{2}} e^{-\gamma/2}\left[(1+\gamma)I_0(\gamma/2)+\gamma I_1(\gamma/2)\right] \\
        & = \frac{1}{4}\sqrt{\frac{\pi}{\gamma}}e^{-\gamma/2}\left[(1+\gamma^{-1})I_0(\gamma/2)+ I_1(\gamma/2)\right] \\
        & := \hat{g}(\gamma).
        \end{aligned}
        \label{eqn:approx evaluation result}
    \end{equation}
    Since the only imprecise step of the above derivation is the asymptotic expansion, the approximation error of the expectation can be upper bounded by the asymptotic expansion error. Assume that the asymptotic expansion error does not exceeds $\delta$, i.e.,
    \begin{equation}
        \lvert x(1-R^2(2\sqrt{x}))-\sqrt{x}/2 \rvert \leq \delta,
        \label{eqn:asymptotic error}
    \end{equation}
    \begin{figure}[ht]
        \centering
        \myincludegraphics{figures/asymptotic_expansion.pdf}
        \caption{The curve $x(1-R^2(2\sqrt{x}))-\sqrt{x}/2$, when $0\leq x\leq 5$. We can see from the curve that the approximation error $\delta \leq 0.07$.}
        \label{fig:asymptotic_expansion}
    \end{figure}
    then we have 
    \begin{equation}
        \left| g(\gamma) - \hat{g}(\gamma)\right| \leq \frac{1}{\gamma^2} \delta. 
    \end{equation}
    We have discovered numerically from Fig.~\ref{fig:asymptotic_expansion} that $\delta \leq 0.07$, and that as $x\to \infty$, the approximation error tends to zero. Thus, \eqref{eqn:approx evaluation result} is a nearly perfect approximation when the interferential SNR $\gamma$ is large. To be more precise, the function $\hat{g}(\gamma)$ has asymptotic expansion at $\gamma \to +\infty$
    \begin{equation}
        \hat{g}(\gamma) \sim \frac{1}{2}\left(\frac{1}{\gamma} + \frac{1}{4\gamma^2} + \mathcal{O}(\frac{1}{\gamma^3})\right).
    \end{equation}
    Thus, $1/\gamma - \hat{g}(\gamma) \sim 1/2\,\Theta(1/\gamma)$, and the relative error of a single term in the CRLB expression is upper bounded by 
    \begin{equation}
        \begin{aligned}
        r & \leq \frac{\delta/\gamma^2}{\lvert \,\lvert 1/\gamma - \hat{g}(\gamma)\rvert - \lvert \hat{g}(\gamma) -  g(\gamma)\rvert\,\rvert} \\
        & \leq \frac{\delta/\gamma^2}{1/((2+\epsilon)\gamma) - \delta/\gamma^2} \\
        & = \frac{\delta}{\gamma/(2+\epsilon) - \delta}, \\
        \end{aligned}
    \end{equation}
    and this upper bound holds whenever $\gamma > (2+\epsilon)\delta$, and $\epsilon$ is chosen to satisfy 
    \begin{equation}
        \frac{1}{\gamma} - \hat{g}(\gamma) > \frac{1}{(2+\epsilon)\gamma}, \forall \gamma > (2+\epsilon)\delta,
    \end{equation}
    which is equivalent to 
    \begin{equation}
        \epsilon > \frac{1}{1-\gamma \hat{g}(\gamma)}-2, \forall \gamma > (2+\epsilon)\delta.
    \end{equation}
    Since the function $ 1/(1-\gamma \hat{g}(\gamma))$ is decreasing on $\gamma>0$, the inequality is equivalent to 
    \begin{equation}
        \epsilon > \frac{1}{1-(2+\epsilon)\delta\, \hat{g}((2+\epsilon)\delta)}-2.
    \end{equation}
    In fact, choosing $\epsilon=4$ will satisfy all the conditions above when $\delta = 0.07$. So the relative error is upper bounded by 
    \begin{equation}
        r \leq \frac{0.07}{\gamma/6 - 0.07}, \forall \gamma > 0.42.
    \end{equation}
    We can easily see from the above inequality that this approximation becomes arbitrarily good when $\gamma\to\infty$.

\footnotesize
\balance 
\bibliographystyle{IEEEtran}
\bibliography{SensingRIS, IEEEabrv}

\end{document}











